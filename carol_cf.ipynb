{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['comprometimento_renda'] = df1[['divida_atual', 'renda_anual']].apply(lambda x: (x['divida_atual'] / x['renda_anual'])*100, axis=1)\n",
    "\n",
    "df1['comprometimento_renda'] = df1['comprometimento_renda'].apply(lambda x:'NÃ£o' if x < 30 \n",
    "                                                                  else 'Sim')\n",
    "\n",
    "\n",
    "df1['num_pgtos_atrasados'] = df1['num_pgtos_atrasados'].apply(lambda x: \n",
    "              'Excelente' if x == 0 else \n",
    "              'Bom' if 1 <= x <= 10 else \n",
    "              'Regular' if 11 <= x <= 20 else 'Ruim' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c63d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f72b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "#normalizacao\n",
    "ss = StandardScaler()\n",
    "\n",
    "# saldo_autal\n",
    "df5['saldo_atual'] = ss.fit_transform( df5[['saldo_atual']].values )\n",
    "pickle.dump( ss, open( 'parameter/saldo_atual_scaler.pkl', 'wb') )\n",
    "\n",
    "# taxa_utilizacao_credito\n",
    "df5['taxa_utilizacao_credito'] = ss.fit_transform( df5[['taxa_utilizacao_credito']].values )\n",
    "pickle.dump( ss, open( 'parameter/taxa_utilizacao_credito_scaler.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaling\n",
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "## Robust Scaler\n",
    "# idade\n",
    "df5['idade'] = rs.fit_transform( df5[['idade']].values )\n",
    "pickle.dump( rs, open( 'parameter/idade_scaler.pkl', 'wb') )\n",
    "\n",
    "\n",
    "# renda_anual\n",
    "df5['renda_anual'] = rs.fit_transform( df5[['renda_anual']].values )\n",
    "pickle.dump( rs, open( 'parameter/renda_anual_scaler.pkl', 'wb') )\n",
    "\n",
    "# valor_em_investimentos\n",
    "df5['valor_em_investimentos'] = rs.fit_transform( df5[['valor_em_investimentos']].values )\n",
    "pickle.dump( rs, open( 'parameter/valor_em_investimentos_scaler.pkl', 'wb') )\n",
    "\n",
    "# num_emprestimos\n",
    "df5['num_emprestimos'] = rs.fit_transform( df5[['num_emprestimos']].values )\n",
    "pickle.dump( rs, open( 'parameter/num_emprestimos_scaler.pkl', 'wb') )\n",
    "\n",
    "# num_contas_bancarias\n",
    "df5['num_contas_bancarias'] = rs.fit_transform( df5[['num_contas_bancarias']].values )\n",
    "pickle.dump( rs, open( 'parameter/num_contas_bancarias_scaler.pkl', 'wb') )\n",
    "\n",
    "# num_cartoes_credito\n",
    "df5['num_cartoes_credito'] = rs.fit_transform( df5[['num_cartoes_credito']].values )\n",
    "pickle.dump( rs, open( 'parameter/num_cartoes_credito_scaler.pkl', 'wb') )\n",
    "\n",
    "# # num_pgtos_atrasados\n",
    "# df5['num_pgtos_atrasados'] = rs.fit_transform( df5[['num_pgtos_atrasados']].values )\n",
    "# pickle.dump( rs, open( 'parameter/num_pgtos_atrasados_scaler.pkl', 'wb') )\n",
    "\n",
    "# num_consultas_credito\n",
    "df5['num_consultas_credito'] = rs.fit_transform( df5[['num_consultas_credito']].values )\n",
    "pickle.dump( rs, open( 'parameter/num_consultas_credito_scaler.pkl', 'wb') )\n",
    "\n",
    "# taxa_juros\n",
    "df5['taxa_juros'] = rs.fit_transform( df5[['taxa_juros']].values )\n",
    "pickle.dump( rs, open( 'parameter/taxa_juros_scaler.pkl', 'wb') )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MinMax Scaler\n",
    "# dias_atraso_dt_venc\n",
    "df5['dias_atraso_dt_venc'] = mms.fit_transform( df5[['dias_atraso_dt_venc']].values )\n",
    "pickle.dump( rs, open( 'parameter/dias_atraso_dt_venc_scaler.pkl', 'wb') )\n",
    "\n",
    "# divida_atual\n",
    "df5['divida_atual'] = mms.fit_transform( df5[['divida_atual']].values )\n",
    "pickle.dump( rs, open( 'parameter/divida_atual_scaler.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "df5['investe_exterior'] = le.fit_transform(df5['investe_exterior'])\n",
    "df5['pessoa_polit_exp'] = le.fit_transform(df5['pessoa_polit_exp'])\n",
    "df5['comprometimento_renda'] = le.fit_transform(df5['comprometimento_renda'])\n",
    "\n",
    "lim_adi_dict = {'Negar': 0, 'Conceder': 1}\n",
    "df5['limite_adicional'] = df5['limite_adicional'].map(lim_adi_dict)\n",
    "\n",
    "pg_atrasados_dict = {'Excelente': 4, 'Bom': 3, 'Regular': 2, 'Ruim': 1}\n",
    "df5['num_pgtos_atrasados'] = df5['num_pgtos_atrasados'].map(pg_atrasados_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dataset entre Treino (80%) e Teste (20%) \n",
    "X = df5.drop('limite_adicional', axis = 1).copy()\n",
    "y = df5['limite_adicional'].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = ms.train_test_split(X, y, stratify = y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65038b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test dataset for boruta\n",
    "x_train_n = x_train.values\n",
    "y_train_n = y_train.values.ravel()\n",
    "\n",
    "# define RadomForestClassifier\n",
    "rf = RandomForestClassifier( n_jobs= -1 ) # warm_start = True,\n",
    "\n",
    "# define boruta\n",
    "boruta = BorutaPy( rf, n_estimators='auto', verbose=2, random_state=42 ).fit( x_train_n, y_train_n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86053760",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_selected = boruta.support_.tolist()\n",
    "\n",
    "# best features\n",
    "x_train_fs = x_train.copy()\n",
    "cols_selected_boruta = x_train_fs.iloc[:, cols_selected].columns.to_list()\n",
    "\n",
    "\n",
    "# not selected boruta\n",
    "cols_not_selected_boruta = list(np.setdiff1d(x_train_fs.columns, cols_selected_boruta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_selected_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8574f509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d71b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSEmProducao",
   "language": "python",
   "name": "dsemproducao"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
